{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718</td>\n",
       "      <td>2014-02-20 10:02:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>890</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:50</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>941.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>942.0</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-22 11:19:51</td>\n",
       "      <td>3847.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>3846.0</td>\n",
       "      <td>2014-02-22 11:19:52</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>2014-02-22 11:20:15</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>2014-02-22 11:20:16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14769</td>\n",
       "      <td>2013-12-16 16:40:17</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2013-12-16 16:40:18</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14769.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-16 16:40:19</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:20</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:21</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:22</td>\n",
       "      <td>14768.0</td>\n",
       "      <td>2013-12-16 16:40:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>782</td>\n",
       "      <td>2014-03-28 10:52:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:52:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:53:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:54:12</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-28 10:54:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:55:42</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:12</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2014-03-28 10:56:42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>2014-02-28 10:53:05</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:22</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:23</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:55:59</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2014-02-28 10:57:06</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2014-02-28 10:57:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1  site2                time2    site3  \\\n",
       "session_id                                                                    \n",
       "1             718  2014-02-20 10:02:45    NaN                  NaN      NaN   \n",
       "2             890  2014-02-22 11:19:50  941.0  2014-02-22 11:19:50   3847.0   \n",
       "3           14769  2013-12-16 16:40:17   39.0  2013-12-16 16:40:18  14768.0   \n",
       "4             782  2014-03-28 10:52:12  782.0  2014-03-28 10:52:42    782.0   \n",
       "5              22  2014-02-28 10:53:05  177.0  2014-02-28 10:55:22    175.0   \n",
       "\n",
       "                          time3    site4                time4  site5  \\\n",
       "session_id                                                             \n",
       "1                           NaN      NaN                  NaN    NaN   \n",
       "2           2014-02-22 11:19:51    941.0  2014-02-22 11:19:51  942.0   \n",
       "3           2013-12-16 16:40:19  14769.0  2013-12-16 16:40:19   37.0   \n",
       "4           2014-03-28 10:53:12    782.0  2014-03-28 10:53:42  782.0   \n",
       "5           2014-02-28 10:55:22    178.0  2014-02-28 10:55:23  177.0   \n",
       "\n",
       "                          time5  ...                  time6    site7  \\\n",
       "session_id                       ...                                   \n",
       "1                           NaN  ...                    NaN      NaN   \n",
       "2           2014-02-22 11:19:51  ...    2014-02-22 11:19:51   3847.0   \n",
       "3           2013-12-16 16:40:19  ...    2013-12-16 16:40:19  14768.0   \n",
       "4           2014-03-28 10:54:12  ...    2014-03-28 10:54:42    782.0   \n",
       "5           2014-02-28 10:55:23  ...    2014-02-28 10:55:59    175.0   \n",
       "\n",
       "                          time7    site8                time8    site9  \\\n",
       "session_id                                                               \n",
       "1                           NaN      NaN                  NaN      NaN   \n",
       "2           2014-02-22 11:19:52   3846.0  2014-02-22 11:19:52   1516.0   \n",
       "3           2013-12-16 16:40:20  14768.0  2013-12-16 16:40:21  14768.0   \n",
       "4           2014-03-28 10:55:12    782.0  2014-03-28 10:55:42    782.0   \n",
       "5           2014-02-28 10:55:59    177.0  2014-02-28 10:55:59    177.0   \n",
       "\n",
       "                          time9   site10               time10 target  \n",
       "session_id                                                            \n",
       "1                           NaN      NaN                  NaN      0  \n",
       "2           2014-02-22 11:20:15   1518.0  2014-02-22 11:20:16      0  \n",
       "3           2013-12-16 16:40:22  14768.0  2013-12-16 16:40:24      0  \n",
       "4           2014-03-28 10:56:12    782.0  2014-03-28 10:56:42      0  \n",
       "5           2014-02-28 10:57:06    178.0  2014-02-28 10:57:11      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_TO_DATA = ('../../data')\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions_Alice.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions_Alice.csv'), index_col='session_id')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44447</th>\n",
       "      <td>runway.blogs.nytimes.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>calotag.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>1.www.s81c.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>www.brgm.fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>www.u88.cn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           site\n",
       "44447  runway.blogs.nytimes.com\n",
       "2458                calotag.com\n",
       "4110             1.www.s81c.com\n",
       "10687               www.brgm.fr\n",
       "11880                www.u88.cn"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''блок, спизженный из базового ядра: \n",
    "# какая-то мутная переобработка столбцов time в тип datetime, в котором они и так уже находятся\n",
    "и сортировка сессий по времени начала (что логично для 30-минутных сессий)\n",
    "'''\n",
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "'''обработка пропущенных данных по сайтам: в данном случае, если данных нет, значит,\n",
    "их никогда и не было (не посетил пользователь аж 10 сайтов за 30 минут, хватило пары).\n",
    "Поэтому смело выставляем время пребывания на сайтах, которые пользователь не посещал, равным 0'''\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "'''\n",
    "Подгружаем словарь возможных сайтов.\n",
    "Заводим под него dataframe (т.е., проиндексированную табличку в один столбец).\n",
    "'''\n",
    "# Load websites dictionary\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()\n",
    "\n",
    "#конец спизженного куска"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "\n",
    "'''ещё один спизженный из базового ядра кусок - делаем данных для тренировки побольше,\n",
    "для этого соединяем train без столбца target с testовой выборкой.\n",
    "На всякий случай запоминаем место, где кончается train и начинается test, но как мы это\n",
    "будем потом использовать - пока что непонятно\n",
    "'''\n",
    "# United dataframe of the initial data \n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# Index to split the training and test data sets\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336358, 20)\n"
     ]
    }
   ],
   "source": [
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#отфильтруем сайты из общих данных\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  56   55    0 ... 1098 1098 1098]\n"
     ]
    }
   ],
   "source": [
    " print(full_sites.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336358, 48371)\n"
     ]
    }
   ],
   "source": [
    "#кусок, спёртый из базового ядра\n",
    "#берём массив идексов для сайтов\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "#print(sites_flatten[:200])\n",
    "\n",
    "#строим какую-то мутную матрицу, хрен пойми зачем. наверное, её и нужно будет заменить на Tf-Idf,\n",
    "#если, конечно, соответствующая процедура тоже возвращает матрицу\n",
    "# and the matrix we are looking for\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]\n",
    "print(full_sites_sparse.shape)\n",
    "#матрица разреженная, очень большая. размерность 1 совпадает с числом сайтов в словаре, \n",
    "#размерность 0 - с числом записей в full_df (количество сессий) \n",
    "#т.е., у нас таблица сесси/сайты, 1 - сайт был просмотрен в сессии, 0 - не был"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_flatten1 = full_sites.to_string(index = False, header = False).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sites_flatten1[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 77307)\t0.5679366365791909\n",
      "  (0, 76129)\t0.547845907916758\n",
      "  (0, 77389)\t0.6142579572215398\n",
      "  (1, 77307)\t0.44294963590589365\n",
      "  (1, 76129)\t0.42728031582168413\n",
      "  (1, 77389)\t0.4790769268600275\n",
      "  (1, 76524)\t0.27829124057086724\n",
      "  (1, 77437)\t0.4621621949074573\n",
      "  (1, 76549)\t0.3172893646694752\n",
      "  (2, 98322)\t0.7231309174833894\n",
      "  (2, 98514)\t0.14878156389677008\n",
      "  (2, 98306)\t0.16320479884930142\n",
      "  (2, 98437)\t0.11127646156746086\n",
      "  (2, 90529)\t0.08994258897039879\n",
      "  (2, 98502)\t0.1734002589164668\n",
      "  (2, 98329)\t0.331822790298673\n",
      "  (2, 98341)\t0.19232016818649045\n",
      "  (2, 98518)\t0.19596592529298001\n",
      "  (2, 98328)\t0.18754552308594596\n",
      "  (2, 98312)\t0.18594822958989943\n",
      "  (2, 98462)\t0.18930280056878676\n",
      "  (2, 98504)\t0.2068350906636841\n",
      "  (2, 98342)\t0.20954168696371916\n",
      "  (3, 98322)\t0.4343055245857754\n",
      "  (3, 98306)\t0.49009621954651084\n",
      "  :\t:\n",
      "  (336355, 60643)\t0.3547406212034198\n",
      "  (336355, 34941)\t0.35149865782625045\n",
      "  (336356, 33155)\t0.1362475609019598\n",
      "  (336356, 25117)\t0.1966016699710323\n",
      "  (336356, 33579)\t0.10610831403137294\n",
      "  (336356, 54644)\t0.23199379152194274\n",
      "  (336356, 98778)\t0.16730849898295838\n",
      "  (336356, 27125)\t0.25413782642386823\n",
      "  (336356, 28707)\t0.26122259029007344\n",
      "  (336356, 79107)\t0.20333517983740584\n",
      "  (336356, 79114)\t0.2264543074172572\n",
      "  (336356, 79115)\t0.23805579328805362\n",
      "  (336356, 92383)\t0.21927124880390936\n",
      "  (336356, 96735)\t0.2438418027565177\n",
      "  (336356, 54653)\t0.32369769969683754\n",
      "  (336356, 28485)\t0.2856043741442199\n",
      "  (336356, 33804)\t0.31679194966201746\n",
      "  (336356, 92384)\t0.2764991684908558\n",
      "  (336356, 28486)\t0.31127781475279465\n",
      "  (336357, 25117)\t0.026512820146702015\n",
      "  (336357, 3049)\t0.6302067655921818\n",
      "  (336357, 3050)\t0.5710299583667605\n",
      "  (336357, 3051)\t0.5089739330632718\n",
      "  (336357, 25254)\t0.09077223711497462\n",
      "  (336357, 25255)\t0.09363346649896102\n"
     ]
    }
   ],
   "source": [
    "#поробуем посмтроить Tf-Idf features\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1, 3), max_features=100000, stop_words=['0'])\n",
    "feats = tf_idf_vect.fit_transform(sites_flatten1)\n",
    "print(feats)\n",
    "#tf_idf_vect.fit_transform(sites_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 54)\t0.6317732460448489\n",
      "  (0, 55)\t0.7751532529648281\n",
      "  (1, 54)\t0.6317732460448489\n",
      "  (1, 55)\t0.7751532529648281\n",
      "  (2, 948)\t0.2464534313966408\n",
      "  (2, 783)\t0.12065719748767129\n",
      "  (2, 947)\t0.14058385131142026\n",
      "  (2, 944)\t0.2202519125196865\n",
      "  (2, 950)\t0.18529867256157573\n",
      "  (2, 945)\t0.9066930156210695\n",
      "  (3, 946)\t0.20871999133515937\n",
      "  (3, 945)\t0.5696329513591194\n",
      "  (3, 948)\t0.258058668664328\n",
      "  (3, 947)\t0.29440759903027613\n",
      "  (3, 944)\t0.6918700420623607\n",
      "  (4, 950)\t0.20277555204892417\n",
      "  (4, 945)\t0.3968839587242487\n",
      "  (4, 951)\t0.26765351568866025\n",
      "  (4, 947)\t0.15384334741720343\n",
      "  (4, 949)\t0.5270828018704868\n",
      "  (4, 946)\t0.6544025815703585\n",
      "  (5, 954)\t0.2672522092651166\n",
      "  (5, 945)\t0.600736524351194\n",
      "  (5, 952)\t0.2422460905720338\n",
      "  (5, 946)\t0.660350082582811\n",
      "  :\t:\n",
      "  (336354, 1215)\t0.30327414266497954\n",
      "  (336354, 1220)\t0.30770776526618454\n",
      "  (336354, 1217)\t0.31665997506686333\n",
      "  (336354, 1221)\t0.3227464843766104\n",
      "  (336354, 301)\t0.5329120382860727\n",
      "  (336354, 299)\t0.5700058351005608\n",
      "  (336355, 6779)\t0.6294053842800151\n",
      "  (336355, 22)\t0.1375263882921609\n",
      "  (336355, 20)\t0.11370967369644508\n",
      "  (336355, 29)\t0.22058274957776572\n",
      "  (336355, 6778)\t0.5607910218560173\n",
      "  (336355, 36)\t0.22192638262693487\n",
      "  (336355, 21)\t0.16290394159256372\n",
      "  (336355, 34)\t0.22484133037987708\n",
      "  (336355, 32)\t0.23524342769651327\n",
      "  (336355, 28)\t0.16486369415737637\n",
      "  (336356, 960)\t0.291244096990489\n",
      "  (336356, 893)\t0.4887387037628022\n",
      "  (336356, 3349)\t0.4582205708939423\n",
      "  (336356, 803)\t0.4450058324089867\n",
      "  (336356, 20)\t0.2942036473613286\n",
      "  (336356, 22)\t0.2372167862750566\n",
      "  (336356, 5827)\t0.35424212501153785\n",
      "  (336357, 1097)\t0.9990480364343389\n",
      "  (336357, 20)\t0.043623627734196174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(full_sites_sparse)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale this features and combine then with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#скалер нужен для какого-то там масштабирования - не то модели, не то данных. \n",
    "#хрен его знает, судя по учебным материалам, хуже не будет\n",
    "scaler = StandardScaler()\n",
    "#завели логрегрессор\n",
    "logit = LogisticRegression(random_state=17, class_weight='balanced')\n",
    "\n",
    "logit_pipe = Pipeline([('scaler', scaler), ('logit', logit)])\n",
    "logit_pipe_params = {'logit__C': np.logspace(-8, 8, 17)}\n",
    "\n",
    "#кросс-валидация. какую брать не знаю, возьму такую для пробы\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "#завели валидатор по сетке\n",
    "grid_search = GridSearchCV(logit_pipe, logit_pipe_params, cv=skf, scoring='roc_auc')\n",
    "#собственно, запуск кросс-валидации, подбор параметров\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "#печать лучших параметров и результатов при них\n",
    "print(round(grid_search.best_score_, 3))\n",
    "print(grid_search.best_index_)\n",
    "print(grid_search.cv_results_['params'][grid_search.best_index_] )\n",
    "print(grid_search.cv_results_['std_test_score'][grid_search.best_index_]/grid_search.best_score_)\n",
    "print((grid_search.cv_results_['std_test_score'][grid_search.best_index_]/grid_search.best_score_ < 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred, \"assignment6_alice_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
